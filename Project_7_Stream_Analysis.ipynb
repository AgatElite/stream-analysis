{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoeLDOR8tGFIHGZZLbqSKQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgatElite/stream-analysis/blob/main/Project_7_Stream_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA7lN7Z8r3hS"
      },
      "outputs": [],
      "source": [
        "# Install kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your kaggle.json file for authentication.\")\n",
        "# Upload the kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the file to the correct location\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "  # specific kaggle folder setup\n",
        "  !mkdir -p ~/.kaggle/\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n",
        "!unzip -o amazon-books-reviews.zip\n",
        "\n",
        "import csv\n",
        "import math\n",
        "import hashlib\n",
        "import random\n",
        "import statistics\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Set to True to process only a small portion of the dataset\n",
        "# Set to False to process the whole stream\n",
        "DEBUG_MODE = False\n",
        "DEBUG_LIMIT = 5000\n",
        "\n",
        "# Dataset filename\n",
        "DATA_FILE = 'Books_rating.csv'\n",
        "\n",
        "print(\"Dataset downloaded and ready.\")"
      ],
      "metadata": {
        "id": "lylWoNLfsc7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stream(filename, limit=None):\n",
        "    \"\"\"\n",
        "    Generator that simulates a stream of data from the CSV file.\n",
        "    Yields one row at a time.\n",
        "    \"\"\"\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        count = 0\n",
        "        for row in reader:\n",
        "            # We are interested in User_id for our stream analysis\n",
        "            user_id = row['User_id']\n",
        "            if user_id:\n",
        "                yield user_id\n",
        "                count += 1\n",
        "                if limit and count >= limit:\n",
        "                    break\n",
        "\n",
        "def distinct_hash(s, index):\n",
        "    \"\"\"\n",
        "    Creates a family of hash functions using md5 and index.\n",
        "    Returns an integer.\n",
        "    \"\"\"\n",
        "    # We combine the string and the index to create independent hash functions\n",
        "    combined = f\"{s}-{index}\"\n",
        "    # Using md5\n",
        "    hex_digest = hashlib.md5(combined.encode('utf-8')).hexdigest()\n",
        "    return int(hex_digest, 16)\n",
        "\n",
        "def trailing_zeros(n):\n",
        "    \"\"\"\n",
        "    Counts the number of trailing zeros in the binary representation of n.\n",
        "    Essential for Flajolet-Martin.\n",
        "    \"\"\"\n",
        "    if n == 0: return 0\n",
        "    s = bin(n)\n",
        "    # Count zeros from the right end\n",
        "    count = 0\n",
        "    for char in reversed(s):\n",
        "        if char == '0':\n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "    return count"
      ],
      "metadata": {
        "id": "aflQDgPXselF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlajoletMartin:\n",
        "    def __init__(self, num_groups=5, hashes_per_group=4):\n",
        "        \"\"\"\n",
        "        Implementation of FM algorithm to estimate distinct elements (F0).\n",
        "        Uses median-of-averages.\n",
        "        \"\"\"\n",
        "        self.num_groups = num_groups\n",
        "        self.hashes_per_group = hashes_per_group\n",
        "\n",
        "        # R_matrix stores the max trailing zeros for each hash function\n",
        "        self.R_matrix = [[0] * hashes_per_group for _ in range(num_groups)]\n",
        "\n",
        "    def process(self, item):\n",
        "        \"\"\"\n",
        "        Process a single item from the stream.\n",
        "        \"\"\"\n",
        "        for i in range(self.num_groups):\n",
        "            for j in range(self.hashes_per_group):\n",
        "                # Unique index for the hash function\n",
        "                func_index = i * self.hashes_per_group + j\n",
        "\n",
        "                # Get hash value\n",
        "                h_val = distinct_hash(item, func_index)\n",
        "\n",
        "                # Count trailing zeros (r(x))\n",
        "                r = trailing_zeros(h_val)\n",
        "\n",
        "                # Maintain global variable R = max(R, r(x))\n",
        "                if r > self.R_matrix[i][j]:\n",
        "                    self.R_matrix[i][j] = r\n",
        "\n",
        "    def estimate(self):\n",
        "        \"\"\"\n",
        "        Returns the estimate of distinct elements.\n",
        "        Estimate ~ 2^R\n",
        "        \"\"\"\n",
        "        group_averages = []\n",
        "\n",
        "        for group in self.R_matrix:\n",
        "            # Calculate 2^R for each hash in the group\n",
        "            estimates = [2**r for r in group]\n",
        "            # Take the Average within the group\n",
        "            group_avg = statistics.mean(estimates)\n",
        "            group_averages.append(group_avg)\n",
        "\n",
        "        # Take the Median of the group averages\n",
        "        final_estimate = statistics.median(group_averages)\n",
        "        return int(final_estimate)"
      ],
      "metadata": {
        "id": "qJp29-mxsgko"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AMS_Estimator:\n",
        "    def __init__(self, num_variables=100):\n",
        "        \"\"\"\n",
        "        Implementation of AMS Algorithm to estimate Second Moment (F2).\n",
        "        Uses Reservoir Sampling.\n",
        "        \"\"\"\n",
        "        self.num_variables = num_variables\n",
        "        # This is the reservoir of variables.\n",
        "        # Each variable stores: {'element': item, 'value': count}\n",
        "        self.variables = [None] * num_variables\n",
        "        self.n = 0 # Current stream length\n",
        "\n",
        "    def process(self, item):\n",
        "        \"\"\"\n",
        "        Process a new item from the stream.\n",
        "        \"\"\"\n",
        "        self.n += 1\n",
        "\n",
        "        # 1. Update existing counters\n",
        "        for i in range(self.num_variables):\n",
        "            if self.variables[i] is not None:\n",
        "                if self.variables[i]['element'] == item:\n",
        "                    self.variables[i]['value'] += 1\n",
        "\n",
        "        # 2. Reservoir Sampling logic for new positions\n",
        "        # We want to pick the current position (n) with probability num_variables / n\n",
        "\n",
        "        # If reservoir is not full, fill it\n",
        "        for i in range(self.num_variables):\n",
        "            if self.variables[i] is None:\n",
        "                self.variables[i] = {'element': item, 'value': 1}\n",
        "                return\n",
        "\n",
        "        prob = self.num_variables / self.n\n",
        "        if random.random() < prob:\n",
        "            # Pick a victim to evict\n",
        "            victim_idx = random.randint(0, self.num_variables - 1)\n",
        "            # Replace it with new variable starting count at 1\n",
        "            self.variables[victim_idx] = {'element': item, 'value': 1}\n",
        "\n",
        "    def estimate(self):\n",
        "        \"\"\"\n",
        "        Calculate F2 estimate based on stored variables.\n",
        "        Y = n * (2 * v - 1)\n",
        "        \"\"\"\n",
        "        total_estimate = 0\n",
        "        valid_vars = 0\n",
        "\n",
        "        for var in self.variables:\n",
        "            if var is not None:\n",
        "                v = var['value']\n",
        "                Y = self.n * (2 * v - 1)\n",
        "                total_estimate += Y\n",
        "                valid_vars += 1\n",
        "\n",
        "        if valid_vars == 0: return 0\n",
        "\n",
        "        # Average the estimates\n",
        "        return int(total_estimate / valid_vars)"
      ],
      "metadata": {
        "id": "4XxcuK2esija"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Initialize algorithms\n",
        "fm_algo = FlajoletMartin(num_groups=5, hashes_per_group=5)\n",
        "ams_algo = AMS_Estimator(num_variables=200)\n",
        "\n",
        "# Ground truth storage\n",
        "exact_counts = {}\n",
        "stream_len = 0\n",
        "\n",
        "# --- METRICS STORAGE ---\n",
        "history_x = []          # Stream position (n)\n",
        "history_fm_est = []     # F0 Estimate\n",
        "history_fm_true = []    # F0 True\n",
        "history_ams_est = []    # F2 Estimate\n",
        "history_ams_true = []   # F2 True\n",
        "timestamps = []         # For scalability analysis\n",
        "\n",
        "start_time = time.time()\n",
        "print(f\"Starting Stream Processing...\")\n",
        "\n",
        "# Process the stream\n",
        "stream = get_stream(DATA_FILE, limit=DEBUG_LIMIT if DEBUG_MODE else None)\n",
        "\n",
        "for user_id in stream:\n",
        "    stream_len += 1\n",
        "\n",
        "    # 1. Update Stream Algorithms\n",
        "    fm_algo.process(user_id)\n",
        "    ams_algo.process(user_id)\n",
        "\n",
        "    # 2. Update Ground Truth (Exact)\n",
        "    if user_id in exact_counts:\n",
        "        exact_counts[user_id] += 1\n",
        "    else:\n",
        "        exact_counts[user_id] = 1\n",
        "\n",
        "# 3. Snapshot Metrics\n",
        "    # We record Time and F0 often as they are fast to compute\n",
        "    if stream_len % 1000 == 0:\n",
        "        est_f0 = fm_algo.estimate()\n",
        "        true_f0 = len(exact_counts)\n",
        "\n",
        "        # F2 ground truth computation is slower: Only calculate Ground Truth every 50000 items\n",
        "        if stream_len % 50000 == 0:\n",
        "            est_f2 = ams_algo.estimate()\n",
        "            true_f2 = sum([c**2 for c in exact_counts.values()]) # The bottleneck\n",
        "\n",
        "            # Store all data points\n",
        "            history_x.append(stream_len)\n",
        "            history_fm_est.append(est_f0)\n",
        "            history_fm_true.append(true_f0)\n",
        "            history_ams_est.append(est_f2)\n",
        "            history_ams_true.append(true_f2)\n",
        "            timestamps.append(time.time() - start_time)\n",
        "\n",
        "            # Print status\n",
        "            print(f\"Processed {stream_len} reviews... F0 Est: {est_f0}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# --- PLOTTING FOR REPORT ---\n",
        "\n",
        "# 1. Flajolet-Martin Convergence Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_x, history_fm_true, label='Ground Truth (Exact)', color='black', linestyle='--')\n",
        "plt.plot(history_x, history_fm_est, label='FM Estimate', color='blue', alpha=0.7)\n",
        "plt.title('Count Distinct (F0): Estimate vs Truth')\n",
        "plt.xlabel('Stream Items Processed')\n",
        "plt.ylabel('Count of Distinct Users')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('f0_convergence.png')\n",
        "plt.show()\n",
        "\n",
        "# 2. AMS Convergence Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_x, history_ams_true, label='Ground Truth (Exact)', color='black', linestyle='--')\n",
        "plt.plot(history_x, history_ams_est, label='AMS Estimate', color='red', alpha=0.7)\n",
        "plt.title('Second Moment (F2): Estimate vs Truth')\n",
        "plt.xlabel('Stream Items Processed')\n",
        "plt.ylabel('Second Moment Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('f2_convergence.png')\n",
        "plt.show()\n",
        "\n",
        "# 3. Scalability (Time vs Input Size)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_x, timestamps, color='green', marker='o', markersize=2)\n",
        "plt.title('Scalability: Execution Time vs Stream Size')\n",
        "plt.xlabel('Stream Items Processed')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.grid(True)\n",
        "plt.savefig('scalability_time.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pzu9rGw9skiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}